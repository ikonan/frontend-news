# Chapter 3. Type Inference and Control Flow Analysis

For programming languages used in industry, “statically typed” and “explicitly typed” have traditionally been synonymous. C, C++, Java: they all made you write out your types. But academic languages never conflated these two things: languages like ML and Haskell have long had sophisticated type inference systems, and this has begun to work its way into industry languages. C++ has added auto, and Java has added var. Newer languages like Rust and Swift have had type inference from the start.

TypeScript makes extensive use of type inference. Used well, this can dramatically reduce the number of type annotations your code requires to get full type safety. One of the easiest ways to tell a TypeScript beginner from a more experienced developer is by the number of type annotations. An experienced TypeScript developer will use relatively few annotations (but use them to great effect), while a beginner may drown their code in redundant type annotations.

In most languages, a variable has a type and it never changes. TypeScript is a bit different. A variable has a type at a location in your code. The process by which its type changes due to surrounding code is known as control flow analysis.

This chapter teaches you how to think about type inference and control flow analysis, shows you some of the problems that can arise with them, and tells you how to fix them. After reading it, you should have a good understanding of how TypeScript infers types, when you still need to write explicit type annotations, and when it’s still a good idea to write type annotations even when a type can be inferred.

## Item 18: Avoid Cluttering Your Code with Inferable Types

The first thing that many new TypeScript developers do when they convert a codebase from JavaScript is fill it with type annotations. TypeScript is about types, after all! But in TypeScript, many annotations are unnecessary. Declaring types for all your variables is counterproductive and is considered poor style.

Don’t write:

```ts
let x: number = 12;
```

Instead, just write:

```ts
let x = 12;
```

If you mouse over x in your editor, you’ll see that its type has been inferred as number (as shown in Figure 3-1).

![](https://cdn-mineru.openxlab.org.cn/extract/e4d7b222-0a3e-4434-a349-f734d14e6c27/8c92bf8b98f9b32d00c743dcc02fe0a491c63e1297e43c171681a74d93d14d63.jpg)  
Figure 3-1. A text editor showing that the inferred type of xis number.

The explicit type annotation is redundant. Writing it just adds noise. If you’re unsure of the type, you can check it in your editor.

TypeScript will also infer the types of more complex objects. Instead of:

```ts
const person: {
  name: string;
  born: { where: string; when: string };
  died: {
    where: string;
    when: string;
  };
} = {
  name: "Sojourner Truth",
  born: { where: "Swartekill, NY", when: "c.1797" },
  died: { where: "Battle Creek, MI", when: "Nov. 26, 1883" },
};
```

you can just write:

```ts
const person = {
  name: "Sojourner Truth",
  born: { where: "Swartekill, NY", when: "c.1797" },
  died: { where: "Battle Creek, MI", when: "Nov. 26, 1883" },
};
```

Again, the types are exactly the same. Writing the type in addition to the value just adds noise here. (Item 20 will explain how TypeScript infers types for object literals.)

What’s true for objects is also true for arrays. TypeScript has no trouble figuring out the return type of this function based on its inputs and operations:

```ts
function square(nums: number[]) {
  return nums.map((x) => x * x);
}
const squares = square([1, 2, 3, 4]); // ^? const squares: number[]
```

TypeScript may infer something more precise than what you expected. This is generally a good thing. For example:

```ts
const axis1: string = "x"; // ^? const axis1: string
const axis2 = "y"; // ^? const axis2: "y"
```

"y" is a more precise type for the axis2 variable. The explicit string annotation on axis1 adds noise and reduces type safety.

Allowing types to be inferred can also facilitate refactoring. Say you have a Product type and a function to log it:

```ts
interface Product {
  id: number;
  name: string;
  price: number;
}

function logProduct(product: Product) {
  const id: number = product.id;
  const name: string = product.name;
  const price: number = product.price;
  console.log(id, name, price);
}
```

At some point you learn that product IDs might have letters in them in addition to numbers. So you change the type of id in Product:

```ts
interface Product {
  id: string;
  name: string;
  price: number;
}
```

Because you included explicit annotations on all the variables in logProduct, this produces an error:

```ts
function logProduct(product: Product) {
  const id: number = product.id;
  // \~\~ Type 'string' is not assignable to type 'number'
  const name: string = product.name;
  const price: number = product.price;
  console.log(id, name, price);
}
```

Had you left off all the annotations in the logProduct function body, the code would have passed the type checker without modification (and worked correctly at runtime, too).

Here’s a better implementation of logProduct that allows the types of all local variables to be inferred (it also switches to destructuring assignment):

```ts
function logProduct(product: Product) {
  const { id, name, price } = product;
  console.log(id, name, price);
}
```

The corresponding version with explicit type annotations is repetitive and cluttered:

```ts
function logProduct(product: Product) {
  const { id, name, price }: { id: string; name: string; price: number } =
    product;
  console.log(id, name, price);
}
```

You can’t put type annotations directly inside the destructuring because, as Item 8 explained, they would be interpreted as renaming directives in value space. Destructuring assignment is a great way to make your code more concise. It encourages consistent naming and it works much better with inferred types.

Explicit type annotations are still required in some situations where TypeScript doesn’t have enough context to determine a type on its own. You have seen one of these before: function parameters.

Some languages will infer types for parameters based on their eventual usage, but TypeScript does not. In TypeScript, a variable’s type is generally determined when it is first introduced. (Item 25 discusses an important exception to this rule.)

Ideal TypeScript code includes type annotations for function/method signatures but not for the local variables created in their bodies. This keeps noise to a minimum and lets readers focus on the implementation logic.

There are some situations where you can leave the type annotations off of function parameters, too. When there’s a default value, for example:

```ts
function parseNumber(str: string, base = 10) {
  // ^? (parameter) base: number
  // ...
}
```

Here the type of base is inferred as number because of the default value of 10.

Parameter types can usually be inferred when the function is used as a callback for a library with type declarations. The declarations on request and response in this example using the express HTTP server library are not required:

```ts
// Don't do this:
app.get("/health", (request: express.Request, response: express.Response) => {
  response.send("OK");
});

// Do this:
app.get("/health", (request, response) => {
  // ^? (parameter) request: Request<...>
  response.send("OK");
  // ^? (parameter) response: Response<...>
});
```

Item 24 has more to say about how context is used in type inference.

There are a few situations where you may still want to specify a type even where it can be inferred.

One is when you define an object literal:

```ts
const elmo: Product = {
  name: "Tickle Me Elmo",
  id: "048188 627152",
  price: 28.99,
};
```

When you specify a type on a definition like this, you enable excess property checking (Item 11). This can help catch errors, particularly for types with optional fields.

You also increase the odds that an error will be reported in the right place. If you leave off the annotation, a mistake in the object’s definition will result in a type error where it’s used, rather than where it’s defined:

```ts
const furby = { name: "Furby", id: 630509430963, price: 35 };
logProduct(furby);
// Argument ... is not assignable to parameter of type 'Product'
// Types of property 'id' are incompatible
// Type 'number' is not assignable to type 'string'
```

In a larger codebase, this type error could appear in a different file with no clear connection to the object definition. With an annotation, you get a more concise error in the exact place where the mistake was made:

```ts
const furby: Product = {
  name: "Furby",
  id: 630509430963,
  // \~\~ Type 'number' is not assignable to type 'string' price: 35,
};
logProduct(furby);
```

Similar considerations apply to a function’s return type. You may still want to annotate this even when it can be inferred to ensure that implementation errors don’t leak out into uses of the function. This is particularly important for exported functions that are part of a public API.

Say you have a function that retrieves a stock quote:

```ts
function getQuote(ticker: string) {
  return fetch(`https://quotes.example.com/?q=${ticker}`).then((response) =>
    response.json()
  );
}
```

You decide to add a cache to avoid duplicating network requests:

```ts
const cache: { [ticker: string]: number } = {};
function getQuote(ticker: string) {
  if (ticker in cache) {
    return cache[ticker];
  }
  return fetch(`https://quotes.example.com/?q=${ticker}`)
    .then((response) => response.json())
    .then((quote) => {
      cache[ticker] = quote;
      return quote as number;
    });
}
```

There’s a mistake in this implementation, which you can see if you look at the inferred return type for getQuote:

```ts
getQuote;
// ^? function getQuote(ticker: string): number | Promise<number>
```

You should really be returning Promise.resolve(cache[ticker]) so that getQuote always returns a Promise. The mistake will most likely produce an error…but in the code that calls getQuote, rather than in getQuote itself:

```ts
getQuote("MSFT").then(considerBuying);
// Property 'then' does not exist on type // 'number | Promise<number>'
```

Had you annotated the intended return type (Promise<number>), the error would have been reported in the correct place:

```ts
const cache: { [ticker: string]: number } = {};
function getQuote(ticker: string): Promise<number> {
  if (ticker in cache) {
    return cache[ticker];
    // \~\~\~ Type 'number' is not assignable to type 'Promise<number>'
  }
  // ...
}
```

When you annotate the return type, it keeps implementation errors from manifesting as errors in user code. This is a particularly good idea for functions like getQuote that have multiple return statements. If you want TypeScript to check that all the returns return the same type, you’ll need to provide a type annotation to tell it your intent.

(Item 27 explains how async functions are an effective way to avoid this particular mistake.)

Writing out the return type may also help you think more clearly about your function: you should know what its input and output types are before you implement it. While the implementation may shift around a bit, the function’s contract (its type signature) generally should not. This is similar in spirit to test-driven development (TDD), in which you write the tests that exercise a function before you implement it. Writing the full type signature first helps get you the function you want, rather than the one the implementation makes expedient.

Another reason to annotate return types is if you want to use a named type. You might choose not to write a return type for this function, for example:

```ts
interface Vector2D {
  x: number;
  y: number;
}
function add(a: Vector2D, b: Vector2D) {
  return { x: a.x + b.x, y: a.y + b.y };
}
```

TypeScript infers the return type as { x: number; y: number; }. This is compatible with Vector2D, but it may be surprising to users of your code when they see Vector2D as a type of the input and not of the output (Figure 3-2).

![](https://cdn-mineru.openxlab.org.cn/extract/e4d7b222-0a3e-4434-a349-f734d14e6c27/28d4378023d2863db77f06df49759c6d7915bb6418a9b172688e9d46bdaed56d.jpg)  
Figure 3-2. The parameters to the ad function have named types, but the inferred return value does not.

If you annotate the return type, the presentation is more straightforward. And if you’ve written documentation on the type (Item 68), it will be associated with the returned value as well. As the complexity of the inferred return type increases, it becomes increasingly helpful to provide a name.

Finally, annotating your return types means that TypeScript has less work to do figuring them out. For large codebases, this can have an impact on compiler performance. Item 78 has more guidance on what to do when your build gets slow.

So should you annotate return types? To reduce code and facilitate refactoring, the default answer is “no.” But it shouldn’t take much to tip you over to “yes.”. If the function has multiple return statements, if it’s part of a public API, or if you want to use a named return type, then add the annotation.

If you are using a linter, the typescript-eslint rule no-inferrable-types (note the variant spelling) can help ensure that all your type annotations are really necessary.

### Things to Remember

- Avoid writing type annotations when TypeScript can infer the same type.
- Ideal TypeScript code has type annotations in function/method signatures but not on local variables in their bodies.
- Consider using explicit annotations for object literals to enable excess property checking and ensure errors are reported close to where they occur.
- Don’t annotate function return types unless the function has multiple returns, is part of a public API, or you want it to return a named type.

## Item 19: Use Different Variables for Different Types

In JavaScript, it’s no problem to reuse a variable to hold a differently typed value for a different purpose:

```ts
let productId = "12-34-56";
fetchProduct(productId); // Expects a string
productId = 123456;
fetchProductBySerialNumber(productId); // excepects a number
```

In TypeScript, this results in two errors:

```ts
let productId = "12-34-56";
fetchProduct(productId);
productId = 123456;
// \~\~ Type 'number' is not assignable to type 'string'
fetchProductBySerialNumber(productId);
// Argument of type 'string' is not assignable to parameter of type 'number'
```

Hovering over the first productId in your editor gives a hint as to what’s going on (see Figure 3-3).

![](https://cdn-mineru.openxlab.org.cn/extract/e4d7b222-0a3e-4434-a349-f734d14e6c27/6c85e81428b5e903e5bec8fa1eb4407416b2fbe42f73723a11a173f703895752.jpg)  
Figure 3-3. The inferred type of productIdis string.

Based on the value "12-34-56", TypeScript has inferred productId’s type as string. You can’t assign a number to a string, hence the error.

This leads us to a key insight about variables in TypeScript: while a variable’s value can change, its type generally does not. The one common way a type can change is to narrow (Item 22), but this involves a type getting smaller, not expanding to include new values. Item 25 presents a notable exception to this rule, but it is an exception and not the rule.

How can you use this idea to fix the example? For productId’s type to not change, it must be broad enough to encompass both strings and numbers. This is the very definition of the union type, string|number:

```ts
let productId: string | number = "12-34-56";
fetchProduct(productId);
productId = 123456; // OK
fetchProductBySerialNumber(productId); // OK
```

This fixes the errors. It’s interesting that TypeScript has been able to determine that id is really a string in the first call and really a number in the second. It has narrowed the union type based on the assignment.

While a union type does work, it may create more issues down the road. Union types are harder to work with than simple types like string or number because you usually have to check what they are before you do anything with them.

The better solution is to introduce a new variable:

```ts
const productId = "12-34-56";
fetchProduct(productId);
const serial = 123456; // OK
fetchProductBySerialNumber(serial); // OK
```

In the previous version, the first and second productId were not semantically related to one another. They were only related by the fact that you reused a variable. This was confusing for the type checker and would be confusing for a human reader, too.

The version with two variables is better for a number of reasons:

- It disentangles two unrelated concepts (ID and serial number).
- It allows you to use more specific variable names.
- It improves type inference. No type annotations are needed.
- It results in simpler types (string and number literals, rather than string| number).
- It lets you declare the variables const rather than let. This make them easier for people and the type checker to reason about.

The general theme, which will come up repeatedly in this chapter, is that mutation makes it harder for the type checker to follow along with your code. Try to avoid type-changing variables. If you can use different names for different concepts, it will make your code clearer both to human readers and to the type checker. You should have far more const than let.

This is not to be confused with “shadowed” variables, as in this example:

```ts
const productId = "12-34-56";
fetchProduct(productId);
{
  const productId = 123456; // OK
  fetchProductBySerialNumber(productId); // OK
}
```

While these two productIds share a name, they are actually two distinct variables with no relationship to one another. It’s fine for them to have different types. While TypeScript is not confused by this, your human readers might be. In general it’s better to use different names for different concepts. Many teams choose to disallow this sort of shadowing via linter rules such as eslint’s no-shadow.

This item focused on scalar values, but similar considerations apply to objects. For more on that, see Item 21.

### Things to Remember

- While a variable’s value can change, its type generally does not.
- To avoid confusion, both for human readers and for the type checker, avoid reusing variables for differently typed values.

## Item 20: Understand How a Variable Gets Its Type

As Item 7 explained, at runtime every variable has a single value. But at static analysis time, when TypeScript is checking your code, a variable has a set of possible values, namely, its type. When you initialize a variable with a constant but don’t provide a type, the type checker needs to decide on one. In other words, it needs to decide on a set of possible values from the single value that you specified. In TypeScript, this process is known as widening. Understanding it will help you make sense of errors and make more effective use of type annotations.

Suppose you’re writing a library to work with vectors. You write out a type for a 3D vector and a function to get the value of any of its components:

```ts
interface Vector3 {
  x: number;
  y: number;
  z: number;
}
function getComponent(vector: Vector3, axis: "x" | "y" | "z") {
  return vector[axis];
}
```

But when you try to use it, TypeScript flags an error:

```ts
let x = "x";
let vec = { x: 10, y: 20, z: 30 };
getComponent(vec, x);
// \~ Argument of type 'string' is not assignable // to parameter of type '"x" | "y" | "z"'
```

This code runs fine, so why the error?

The issue is that x’s type is inferred as string, whereas the getComponent function expected a more specific type for its second argument. This is widening at work, and here it has led to a type error.

Widening is ambiguous in the sense that there are many possible types for any given value. In this statement, for example:

```ts
const mixed = ["x", 1];
```

what should the type of mixed be? Here are a few possibilities:

```ts
('x' | 1)[]
['x', 1]
[string, number]
readonly [string, number]
(string|number)[]
readonly (string|number)[]
[any, any]
any[]
```

Without more context, TypeScript has no way to know which one is “right.” It has to guess at your intent. (In this case, it guesses (string|number)[].) And smart as it is, TypeScript can’t read your mind. It won’t get this right 100% of the time. The result is inadvertent errors like the one we just saw.

In the initial example, the type of x is inferred as string because TypeScript chooses to allow code like this:

```ts
let x = 'x';
x = 'a'
x = 'Four score and seven years ago...
```

But it would also be valid JavaScript to write:

```ts
let x = "x";
x = /x|y|z/;
x = ["x", "y", "z"];
```

In inferring the type of x as string, TypeScript attempts to strike a balance between specificity and flexibility. A variable’s type won’t change to something completely different after it’s declared (Item 19), so string makes more sense than string|RegExp or string|string[] or any.

The general rule for primitive values assigned with let is that they expand to their “base type”: "x" expands to string, 39 expands to number, true expands to boolean and so on. (null and undefined are handled differently, see Item 25.)

TypeScript gives you a few ways to control the process of widening. One is const. If you declare a variable with const instead of let, it gets a narrower type. In fact, using const fixes the error in our original example:

```ts
const x = "x"; // ^? const x: "x"
let vec = { x: 10, y: 20, z: 30 };
getComponent(vec, x); // OK
```

Because x cannot be reassigned, TypeScript is able to infer a more precise type without risk of inadvertently flagging errors on subsequent assignments. And because the string literal type "x" is assignable to "x"|"y"|"z", the code passes the type checker.

const isn’t a panacea, however. For objects and arrays, there is still ambiguity. The mixed example illustrated the issue for arrays: should TypeScript infer a tuple type? What type should it infer for the elements?

Similar issues arise with objects. This code is fine in JavaScript:

```ts
const obj = { x: 1 };
obj.x = 3;
obj.x = "3";
obj.y = 4;
obj.z = 5;
obj.name = "Pythagoras";
```

The type of obj could be inferred anywhere along the spectrum of specificity. At the specific end is {readonly x: 1}. More general is {x: number}. More general still would be {[key: string]: number}, object or, most general of all, any, or unknown.

In the case of objects, TypeScript infers what it calls the “best common type.” It determines this by treating each property as though it were assigned with let. So the type of obj comes out as {x: number}. This lets you reassign obj.x to a different number, but not to a string. And it prevents you from adding other properties via direct assignment. (This is a good reason to build objects all at once, as explained in Item 21.)

So the last four statements are errors:

```ts
const obj = {
  x: 1,
};
obj.x = 3; // OK
obj.x = "3";
// \~ Type 'string' is not assignable to type 'number'
obj.y = 4;
// \~ Property 'y' does not exist on type '{ x: number; }'
obj.z = 5;
// \~ Property 'z' does not exist on type '{ x: number; }'
obj.name = "Pythagoras";
// \~\~\~ Property 'name' does not exist on type '{ x: number; }'
```

Again, TypeScript is trying to strike a balance between specificity and flexibility. It needs to infer a specific enough type to catch errors, but not such a specific type that it creates false positives. It does this by inferring a type of number for a property initialized to a value like 1.

If you know better, there are a few ways to override TypeScript’s default behavior. One is to supply an explicit type annotation:

```ts
const obj: { x: string | number } = { x: 1 }; // ^? const obj: { x: string | number; }
```

Another is to provide additional context to the type checker, e.g., by passing the value as an argument to a function (Item 24).

A third way is with a const assertion. This is not to be confused with let and const, which introduce symbols in value space. This is a purely typelevel construct. Look at the different inferred types for these variables:

```ts
const obj1 = { x: 1, y: 2 };
// ^? const obj1: { x: number; y: number; }
const obj2 = { x: 1 as const, y: 2 };
// ^? const obj2: { x: 1; y: number; }
const obj3 = { x: 1, y: 2 } as const;
// ^? const obj3: { readonly x: 1; readonly y: 2; }
```

When you write as const after a value, TypeScript will infer the narrowest possible type for it. There is no widening. For true constants, this is typically what you want. You can also use as const with arrays to infer a tuple type:

```ts
const arr1 = [1, 2, 3]; // ^? const arr1: number[]
const arr2 = [1, 2, 3] as const; // ^? const arr2: readonly [1, 2, 3]
```

Despite the similar syntax, a const assertion should not be confused with a type assertion (as T). While type assertions are best avoided (Item 9), a const assertion doesn’t compromise type safety and is always OK.

There’s a handy trick if you want TypeScript to infer a tuple type instead of an array type, but still allow the type of each element in the tuple to widen to its base type / best common type:

```ts
function tuple<T extends unknown[]>(...elements: T) {
  return elements;
}
const arr3 = tuple(1, 2, 3);
// ^? const arr3: [number, number, number]
const mix = tuple(4, "five", true);
// ^? const mix: [number, string, boolean]
```

The tuple function here serves no purpose at runtime, but guides TypeScript toward inferring the type you want. Another function that can guide inference is JavaScript’s Object.freeze:

```ts
const frozenArray = Object.freeze([1, 2, 3]);
// ^? const frozenArray: readonly number[]
const frozenObj = Object.freeze({ x: 1, y: 2 });
// ^? const frozenObj: Readonly<{ x: 1; y: 2; }>
```

Like a const assertion, Object.freeze has introduced some readonly modifiers into the inferred types (though it displays differently, the type of frozenObj is exactly the same as obj3). Unlike a const assertion, the “freeze” will be enforced by your JavaScript runtime. But it’s a shallow freeze/readonly, whereas a const assertion is deep. Item 14 discusses readonly and how it can help prevent mistakes.

Finally, a fourth way to control widening is the satisfies operator. This ensures that a value, well, satisfies the requirements of a type and guides inference by preventing TypeScript from inferring a wider type. Here’s how it works:

```ts
type Point = [number, number];
const capitals1 = { ny: [-73.7562, 42.6526], ca: [-121.4944, 38.5816] }; 
// ^? const capitals1: { ny: number[]; ca: number[]; }
const capitals2 = {
  ny: [-73.7562, 42.6526],
  ca: [-121.4944, 38.5816],
} satisfies Record<string, Point>;
capitals2;
// ^? const capitals2: { ny: [number, number]; ca: [number, number]; }
```

Left to its own devices, TypeScript takes the keys from the object literal and widens the values to number[], just as it would with let. With satisfies, we prevent the values from being widened beyond the Point type.

Compare this to what you get from an annotation using the same type:

```ts
const capitals3: Record<string, Point> = capitals2;
capitals3.pr; // undefined at runtime
// ^? Point
capitals2.pr;
// \~\~ Property 'pr' does not exist on type '{ ny: ...; ca: ...; }'
```

The type coming from satisfies has precise keys, which helps to catch errors.

The satisfies operator will report an error if part of the object isn’t assignable to the type:

```ts
const capitalsBad = {
  ny: [-73.7562, 42.6526, 148],
  // \~\~ Type '[number, number, number]' is not assignable to type 'Point'. ca: [-121.4944, 38.5816, 26],
  // \~\~ Type '[number, number, number]' is not assignable to type 'Point'.
} satisfies Record<string, Point>;
```

This is an improvement over a const assertion because it will report the error where you define the object, rather than where you use it.

If you’re getting incorrect errors that you think are due to widening, consider changing let to const, adding some explicit type annotations, using a helper function like tuple or Object.freeze, or using a const assertion or a satisfies clause. As always, inspecting types in your editor is the key to building an intuition for how this works (see Item 6).

### Things to Remember

- Understand how TypeScript infers a type from a literal by widening it.
- Familiarize yourself with the ways you can affect this behavior: const, type annotations, context, helper functions, as const, and satisfies.

## Item 21: Create Objects All at Once

As Item 19 explained, while a variable’s value may change, its type in TypeScript generally does not. This makes some JavaScript patterns easier to model in TypeScript than others. In particular, it means that you should prefer creating objects all at once, rather than piece by piece.

Here’s one way to create an object representing a two-dimensional point in JavaScript:

```ts
const pt = {};
pt.x = 3;
pt.y = 4;
```

In TypeScript, this will produce errors on each assignment:

```ts
const pt = {};
// ^? const pt: {}
pt.x = 3;
// \~ Property 'x' does not exist on type '{}'
pt.y = 4;
// \~ Property 'y' does not exist on type '{}'
```

This is because the type of pt on the first line is inferred based on its value {}, and you may only assign to known properties.

You get the opposite problem if you define a Point interface:

```ts
interface Point {
  x: number;
  y: number;
}
const pt: Point = {};
// \~\~ Type '{}' is missing the following properties from type 'Point': x, y
pt.x = 3;
pt.y = 4;
```

A type assertion seems to offer a solution:

```ts
const pt = {} as Point; // ^? const pt: Point
pt.x = 3;
pt.y = 4; // OK
```

The problem with this pattern is that TypeScript won’t check that you’ve assigned all the properties to pt before using it. If you dropped the assignment to pt.y, for example, the code would still pass the type checker but might lead to NaNs or runtime exceptions. As Item 9 explained, type assertions shouldn’t be the first tool you reach for.

The best solution is to define the object all at once with a type declaration:

```ts
const pt: Point = { x: 3, y: 4 };
```

If you need to build a larger object from smaller ones, avoid doing it in multiple steps:

```ts
const pt = { x: 3, y: 4 };
const id = { name: "Pythagoras" };
const namedPoint = {};
Object.assign(namedPoint, pt, id);
namedPoint.name;
// \~\~\~\~ Property 'name' does not exist on type '{}'
```

You can build the larger object all at once instead using object spread syntax, ...:

```ts
const namedPoint = { ...pt, ...id };
// ^? const namedPoint: { name: string; x: number; y: number; }
namedPoint.name; // OK
// ^? (property) name: string
```

You can also use object spread syntax to build up objects field by field in a type-safe way. The key is to use a new variable on every update so that each gets a new type (Item 19):

```ts
const pt0 = {};
const pt1 = { ...pt0, x: 3 };
const pt: Point = { ...pt1, y: 4 }; // OK
```

The type declaration on the final line ensures that we’ve added all the necessary properties. While this is a roundabout way to build up such a simple object, it can be a useful technique for adding properties to an object and allowing TypeScript to infer a new type.

To conditionally add a property in a type-safe way, you can use spread syntax with {} or any falsy value (null, undefined, false, etc.), which add no properties:

```ts
declare let hasMiddle: boolean;
const firstLast = { first: "Harry", last: "Truman" };
const president = { ...firstLast, ...(hasMiddle ? { middle: "S" } : {}) };
// ^? const president: {
// middle?: string;
// first: string;
// last: string;
// }
// or: const president = {...firstLast, ...(hasMiddle && {middle: 'S'})};
```

As you can see, the inferred type has an optional property.

You can also use spread syntax to add multiple fields conditionally:

```ts
declare let hasDates: boolean;
const nameTitle = { name: "Khufu", title: "Pharaoh" };
const pharaoh = { ...nameTitle, ...(hasDates && { start: -2589, end: -2566 }) };
// ^? const pharaoh: {
// start?: number;
// end?: number;
// name: string;
// title: string;
// }
```

In this case, both start and end have become optional fields. If you read start off this type, you’ll have to consider the possibility that it’s undefined:

Sometimes you want to build an object or array by transforming another one. In this case, the equivalent of “building objects all at once” is using built-in functional constructs or utility libraries like Lodash rather than loops. See Item 26 for more on this.

### Things to Remember

- Prefer to build objects all at once rather than piecemeal.
- Use multiple objects and object spread syntax ({...a, ...b}) to add properties in a type-safe way.
- Know how to conditionally add properties to an object.

## Item 22: Understand Type Narrowing

Narrowing, or “refinement,” is the process by which TypeScript goes from a broad type to a more specific one. Perhaps the most common example of this is null checking:

```ts
const elem = document.getElementById("what-time-is-it");
// ^? const elem: HTMLElement | null
if (elem) {
  elem.innerHTML = "Party Time".blink();
  // ^? const elem: HTMLElement
} else {
  elem;
  // ^? const elem: null
  alert("No element #what-time-is-it");
}
```

If elem is null, then the code in the first branch won’t execute. So TypeScript is able to exclude null from the union type within this block, resulting in a narrower type which is much easier to work with. Because the compiler is following the paths of execution of your code, this is also

known as control flow analysis. The type checker is generally quite good at following your logic and narrowing types in conditionals like these, though it can occasionally be thwarted by aliasing (Item 23).

Notice how the same symbol, elem, has different static types at different locations in your code. This is a somewhat unusual ability amongst programming languages: in C++, Java, and Rust, for example, a variable has a single type for its entire lifetime. If you want to narrow its type, you also need to create a new variable. But in TypeScript, a symbol has a type at a location. Learn to take advantage of this and you’ll write more concise, idiomatic TypeScript.

There are many ways that you can narrow a type. Throwing or returning from a branch will narrow a variable’s type for the rest of a block:

```ts
const elem = document.getElementById("what-time-is-it"); // ^? const elem: HTMLElement | null
if (!elem) throw new Error("Unable to find #what-time-is-it");
elem.innerHTML = "Party Time".blink();
// ^? const elem: HTMLElement
```

You can also use instanceof:

```ts
function contains(text: string, search: string | RegExp) {
  if (search instanceof RegExp) {
    return !!search.exec(text);
  } // ^? (parameter) search: RegExp
  return text.includes(search);
  // ^? (parameter) search: string
}
```

A property check also works:

```ts
interface Apple {
  isGoodForBaking: boolean;
}
interface Orange {
  numSlices: number;
}
function pickFruit(fruit: Apple | Orange) {
  if ("isGoodForBaking" in fruit) {
    fruit; // ^? (parameter) fruit: Apple
  } else {
    fruit; // ^? (parameter) fruit: Orange
  }
  fruit; // ^? (parameter) fruit: Apple | Orange
}
```

Some built-in functions such as Array.isArray are also able to narrow types:

```ts
function contains(text: string, terms: string | string[]) {
  const termList = Array.isArray(terms) ? terms : [terms]; // ^? const termList: string[] //
}
```

TypeScript is generally quite good at tracking types through conditionals. Think twice before adding a type assertion—it might be on to something that you’re not! For example, this is the wrong way to exclude null from a union type:

```ts
const elem = document.getElementById("what-time-is-it");
// ^? const elem: HTMLElement | null
if (typeof elem === "object") {
  elem; // ^? const elem: HTMLElement | null
}
```

Because typeof null is "object" in JavaScript, you have not, in fact, excluded null with this check!1 Similar surprises can come from falsy primitive values:

```ts
function maybeLogX(x?: number | string | null) {
  if (!x) {
    console.log(x); // ^? (parameter) x: string | number | null | undefined
  }
}
```

Because the empty string and 0 are both falsy, x could still be a string or number in that branch. TypeScript is right!

Another common way to help the type checker narrow your types is by putting an explicit “tag” on them:

```ts
interface UploadEvent {
  type: "upload";
  filename: string;
  contents: string;
}
interface DownloadEvent {
  type: "download";
  filename: string;
}
type AppEvent = UploadEvent | DownloadEvent;
function handleEvent(e: AppEvent) {
  switch (e.type) {
    case "download":
      console.log("Download", e.filename); // ^? (parameter) e: DownloadEvent
      break;
    case "upload":
      console.log("Upload", e.filename, e.contents.length, "bytes"); // ^? (parameter) e: UploadEvent
      break;
  }
}
```

This is known as a “tagged union” or “discriminated union,” and it is ubiquitous in TypeScript. Chapter 4 will revisit this pattern. When you write switch statements, it’s a good idea to test that you’ve covered all possibilities. Item 59 shows you how.

If TypeScript isn’t able to figure out a type, you can introduce a special function to help it out:

```ts
function isInputElement(el: Element): el is HTMLInputElement {
  return "value" in el;
}
function getElementContent(el: HTMLElement) {
  if (isInputElement(el)) {
    return el.value; // ^? (parameter) el: HTMLInputElement
  }
  return el.textContent; // ^? (parameter) el: HTMLElement
}
```

This is known as a “user-defined type guard,” and the el is HTMLInputElement clause is called a “type predicate.” As a return type, this type tells the type checker that it can narrow the type of the parameter if the function returns true.

Some functions are able to use type guards to narrow types in arrays or objects, notably the filter method on Arrays:

```ts
const formEls = document.querySelectorAll(".my-form *");
const formInputEls = [...formEls].filter(isInputElement); // ^? const formInputEls: HTMLInputElement[]
```

It’s important to note user-defined type guards are no safer than a type assertion (el as HTMLInputElement): there’s nothing checking that the body of a type guard corresponds to the type predicate it returns. (In this case, in fact, there are a few Elements with a value property that are not HTMLInputElements.)

You can often rework your code slightly to help TypeScript follow along. This code using a Map is correct but produces a type error:

```ts
const nameToNickname = new Map<string, string>();
declare let yourName: string;
let nameToUse: string;
if (nameToNickname.has(yourName)) {
  nameToUse = nameToNickname.get(yourName);
  // \~\~\~ Type 'string | undefined' is not assignable to type 'string'.
} else {
  nameToUse = yourName;
}
```

The issue is that TypeScript doesn’t understand the relationship between the has and get methods of a Map. It doesn’t know that checking has eliminates the possibility of undefined in a subsequent lookup with get. A slight change eliminates the type error (and preserves the behavior):

```ts
const nickname = nameToNickname.get(yourName);
let nameToUse: string;
if (nickname !== undefined) {
  nameToUse = nickname;
} else {
  nameToUse = yourName;
}
```

This pattern is common and can be written more concisely using the “nullish coalescing” operator (??):

```ts
const nameToUse = nameToNickname.get(yourName) ?? yourName;
```

If you find yourself fighting with the type checker in a conditional, think about whether you can rework it to help TypeScript follow along.

It’s also helpful to understand when types don’t narrow. One notable example is in callbacks:

```ts
function logLaterIfNumber(obj: { value: string | number }) {
  if (typeof obj.value == "number") {
    setTimeout(() => console.log(obj.value.toFixed()));
    // Property 'toFixed' does not exist on type 'string | number'.
  }
}
```

We’ve done a typeof check which should narrow the type of obj.value. So why did it revert back to the union type, which produced a type error?

It’s because the calling code might look like this:

```ts
const obj: { value: string | number } = { value: 123 };
logLaterIfNumber(obj);
obj.value = "Cookie Monster";
```

By the time the callback runs, the type of obj.value has changed, invalidating the refinement. This code throws an exception at runtime, and TypeScript is right to warn you about it.

Understanding how types narrow will help you build an intuition for how type inference works, make sense of errors, and generally have a more productive relationship with the type checker.

### Things to Remember

- Understand how TypeScript narrows types based on conditionals and other types of control flow.
- Use tagged/discriminated unions and user-defined type guards to help the process of narrowing.
- Think about whether code can be refactored to let TypeScript follow along more easily.

## Item 23: Be Consistent in Your Use of Aliases

When you introduce a new name for a value:

```ts
const place = { name: "New York", latLng: [41.6868, -74.2692] };
const loc = place.latLng;
```

you have created an alias. Changes to properties on the alias will be visible on the original value as well:

> loc[0] = 0; 0 > place.latLng [ 0, -74.2692 ]

If you’ve used a language that has pointer or reference types, this is the same idea. There are two variables that point to the same underlying object.

Aliases are the bane of compiler writers in all languages because they make control flow analysis difficult. If you’re deliberate in your use of aliases, TypeScript will be able to understand your code better and help you find more real errors.

Suppose you have a data structure that represents a polygon:

```ts
interface Coordinate {
  x: number;
  y: number;
}

interface BoundingBox {
  x: [number, number];
  y: [number, number];
}

interface Polygon {
  exterior: Coordinate[];
  holes: Coordinate[][];
  bbox?: BoundingBox;
}
```

The geometry of the polygon is specified by the exterior and holes properties. (The holes array lets you represent doughnut shapes, which have holes in the interior.) The bbox property is an optimization that may or may not be present. You can use it to speed up a point-in-polygon check:

```ts
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  if (polygon.bbox) {
    if (
      pt.x < polygon.bbox.x[0] ||
      pt.x > polygon.bbox.x[1] ||
      pt.y < polygon.bbox.y[0] ||
      pt.y > polygon.bbox.y[1]
    ) {
      return false;
    }
  } // ... more complex check
}
```

This code works (and type checks) but is a bit repetitive: polygon.bbox appears five times in three lines! Here’s an attempt to factor out an intermediate variable to reduce duplication:

```ts
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  const box = polygon.bbox;
  if (polygon.bbox) {
    if (
      pt.x < box.x[0] ||
      pt.x > box.x[1] || // 'box' is possibly 'undefined'
      pt.y < box.y[0] ||
      pt.y > box.y[1]
    ) {
      // 'box' is possibly 'undefined'
      return false;
    }
  }
  // ...
}
```

This code still works, so why the error? By factoring out the box variable, you’ve created an alias for polygon.bbox, and this has thwarted the control flow analysis that quietly worked in the first example.

You can inspect the types of box and polygon.bbox to see what’s happening:

```ts
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  polygon.bbox; // ^? (property) Polygon.bbox?: BoundingBox | undefined
  const box = polygon.bbox; // ^? const box: BoundingBox | undefined
  if (polygon.bbox) {
    console.log(polygon.bbox); // ^? (property) Polygon.bbox?: BoundingBox
    console.log(box); // ^? const box: BoundingBox | undefined
  }
}
```

The property check refines the type of polygon.bbox but not the type of box, hence the errors. This leads us to the golden rule of aliasing: if you introduce an alias, use it consistently.

Using box in the property check fixes the error:

```ts
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  const box = polygon.bbox;
  if (box) {
    if (
      pt.x < box.x[0] ||
      pt.x > box.x[1] ||
      pt.y < box.y[0] ||
      pt.y > box.y[1]
    ) {
      // OK
      return false;
    }
  } //
}
```

The type checker is happy now, but there’s an issue for human readers. We’re using two names for the same thing: box and bbox. This is a distinction without a difference (Item 41).

Object destructuring syntax rewards consistent naming by letting us write more concise code. You can even use it on arrays and nested structures:

```ts
function isPointInPolygon(polygon: Polygon, pt: Coordinate) {
  const { bbox } = polygon;
  if (bbox) {
    const { x, y } = bbox;
    if (pt.x < x[0] || pt.x > x[1] || pt.y < y[0] || pt.y > y[1]) {
      return false;
    }
  }
  // ...
}
```

A few other points:

This code would have required more property checks if the x and y properties had been optional, rather than the whole bbox property. We benefited from following the advice of Item 33, which discusses the importance of pushing null values to the perimeter of your types. An optional property was appropriate for bbox but would not have been appropriate for holes. If holes was optional, then it would be possible for it to be either missing or an empty array ([]). This would be a distinction without a difference. An empty array is a fine way to indicate “no holes.”

In your interactions with the type checker, don’t forget that aliasing can introduce confusion at runtime, too:

```ts
const { bbox } = polygon;
if (!bbox) {
  calculatePolygonBbox(polygon); // Fills in polygon.b ox
  // Now polygon.bbox and bbox refer to different values!
}
```

TypeScript’s control flow analysis tends to be quite good for local variables. But for properties you should be on guard:

```ts
function expandABit(p: Polygon) {
  /* ... */
}
polygon.bbox;
// ^? (property) Polygon.bbox?: BoundingBox | undefined
if (polygon.bbox) {
  polygon.bbox; // ^? (property) Polygon.bbox?: BoundingBox
  expandABit(polygon);
  polygon.bbox; // ^? (property) Polygon.bbox?: BoundingBox
}
```

The call to expandABit(polygon) could very well un-set polygon.bbox, so it would be safer for the type to revert to BoundingBox | undefined. But this would get frustrating: you’d have to repeat your property checks every time you called a function. So TypeScript makes the pragmatic choice to assume the function does not invalidate its type refinements. Item 48 discusses other situations like this where TypeScript trades safety for convenience.

If you’d factored out a local bbox variable instead of using polygon.bbox, the type of bbox would remain accurate, but it might no longer be the same value as polygon.bbox. If you’re concerned about these sorts of side effects, the best option is to pass a read-only version of polygon to the function (Item 14). By preventing mutation, we also improve type safety. This is a concern specifically for object types (including arrays) because they are mutable. Primitive values (numbers, strings, etc.) are already immutable.

### Things to Remember

- Aliasing can prevent TypeScript from narrowing types. If you create an alias for a variable, use it consistently.
- Be aware of how function calls can invalidate type refinements on properties. Trust refinements on local variables more than on properties.

## Item 24: Understand How Context Is Used in Type Inference

TypeScript doesn’t just infer types based on values. It also considers the context in which the value occurs. This usually works well but can sometimes lead to surprises. Understanding how context is used in type inference will help you identify and work around these surprises when they do occur.

In JavaScript, you can factor out an expression into a constant without changing the behavior of your code (so long as you don’t alter execution order). In other words, these two statements are equivalent:

```ts
// Inline form
setLanguage("JavaScript");

// Reference form
let language = "JavaScript";
setLanguage(language);
```

In TypeScript, this refactor still works:

```ts
function setLanguage(language: string) {
  /* ... */
}
setLanguage("JavaScript"); // OK
let language = "JavaScript";
setLanguage(language); // OK
```

Now suppose you take to heart the advice of Item 35 and replace the string type with a more precise union of string literal types:

```ts
type Language = "JavaScript" | "TypeScript" | "Python";
function setLanguage(language: Language) {
  /* ... */
}
setLanguage("JavaScript"); // OK

let language = "JavaScript";
setLanguage(language);
// Argument of type 'string' is not assignable
// to parameter of type 'Language'
```

What went wrong? With the inline form, TypeScript knows from the function declaration that the parameter is supposed to be of type Language. The string literal 'JavaScript' is assignable to this type, so this is OK. But when you factor out a variable, TypeScript must infer its type at the time of assignment. It applies the usual algorithm (Item 20) and infers string, which is not assignable to Language. Hence the error.

**NOTE**

> Some languages are able to infer types for variables based on their eventual usage. But this can also be confusing. Anders Hejlsberg, the creator of TypeScript, refers to it as “spooky action at a distance.” By and large, TypeScript determines the type of a variable when it is first introduced. For a notable exception to this rule, see Item 25.

There are two good ways to solve this problem. One is to constrain the possible values of language with a type annotation:

```ts
let language: Language = "JavaScript";
setLanguage(language); // OK
```

This also has the benefit of flagging an error if there’s a typo in the language—for example 'Typescript' (it should be a capital “S”).

The other solution is to make the variable constant:

```ts
const language = "JavaScript"; // ^? const language: "JavaScript"
setLanguage(language); // OK
```

By using const, we’ve told the type checker that this variable cannot change. So TypeScript can infer a more precise type for language, namely the string literal type "JavaScript". This is assignable to Language so the code type checks. Of course, if you do need to reassign language, then you’ll need to use the type annotation.

The fundamental issue here is that we’ve separated the value from the context in which it’s used. Sometimes this is OK, but often it is not. The rest of this item walks through a few cases where this loss of context can cause errors and shows you how to fix them.

### Tuple Types

In addition to string literal types, problems can come up with tuple types. Suppose you’re working with a map visualization that lets you programmatically pan the map:

```ts
// Parameter is a (latitude, longitude) pair.
function panTo(where: [number, number]) {
  /* ... */
}
panTo([10, 20]); // OK
const loc = [10, 20];
// ^? const loc: number[]
panTo(loc);
// Argument of type 'number[]' is not assignable to
// parameter of type '[number, number]'
```

As before, you’ve separated a value from its context. In the first instance, [10, 20] is assignable to the tuple type [number, number]. In the second, TypeScript infers the type of loc as number[] (i.e., an array of numbers of unknown length). This is not assignable to the tuple type, since many arrays have the wrong number of elements.

So how can you fix this error without resorting to any? You’ve already declared it const, so that won’t help. But you can still provide a type annotation to let TypeScript know precisely what you mean:

```ts
const loc: [number, number] = [10, 20];
panTo(loc); // OK
```

As Item 20 explained, another way is to provide a “const context.” This tells TypeScript that you intend the value to be deeply constant, rather than the shallow constant that const gives:

```ts
const loc = [10, 20] as const;
// ^? const loc: readonly [10, 20]
panTo(loc);
// The type 'readonly [10, 20]' is 'readonly'
// and cannot be assigned to the mutable type '[number, number]'
```

The type of loc is now inferred as readonly [10, 20], rather than number[]. Unfortunately this is too precise! The type signature of panTo makes no promises that it won’t modify the contents of its where parameter. Since the loc parameter has a readonly type, this won’t do.

The best solution here is to add a readonly annotation to the panTo function:

```ts
function panTo(where: readonly [number, number]) {
  /* ... */
}
const loc = [10, 20] as const;
panTo(loc); // OK
```

If the type signature is outside your control, then you’ll need to use an annotation. (Item 14 has more to say about readonly and type safety.)

const contexts can neatly solve issues around losing context in inference, but they do have an unfortunate downside: if you make a mistake in the definition (say you add a third element to the tuple), then the error will be flagged at the call site, not at the definition. This may be confusing, especially if the error occurs in a deeply nested object that’s used far from where it’s defined:

```ts
const loc = [10, 20, 30] as const; // error is real y here.
panTo(loc);
// \~\~\~ Argument of type 'readonly [10, 20, 30]' is not assignable to
// parameter of type 'readonly [number, number]'
// Source has 3 element(s) but target allows only 2.
```

For this reason, it’s preferable to use the inline form or apply a type declaration.

### Objects

The problem of separating a value from its context also comes up when you factor out a constant from a larger object that contains some string literals or tuples. For example:

```ts
type Language = "JavaScript" | "TypeScript" | "Python";
interface GovernedLanguage {
  language: Language;
  organization: string;
}
function complain(language: GovernedLanguage) {
  /* ... */
}
complain({ language: "TypeScript", organization: "Microsoft" }); // OK
const ts = { language: "TypeScript", organization: "Microsoft" };
complain(ts);
// \~\~ Argument of type '{ language: string; organization: string; }'
// is not assignable to parameter of type 'GovernedLanguage'
// Types of property 'language' are incompatible
// Type 'string' is not assignable to type 'Language'
```

In the ts object, the type of language is inferred as string. As before, the solution is to add a type annotation (const ts: GovernedLanguage = ...), use a const assertion (as const), or the satisfies operator (Item 20).

### Callbacks

When you pass a callback to another function, TypeScript uses context to infer the parameter types of the callback:

```ts
function callWithRandomNumbers(fn: (n1: number, n2: number) => void) {
  fn(Math.random(), Math.random());
}
callWithRandomNumbers((a, b) => {
  // ^? (parameter) a: number
  console.log(a + b);
  // ^? (parameter) b: number
});
```

The types of a and b are inferred as number because of the type declaration for callWithRandomNumbers. If you factor the callback out into a constant, you lose that context and get noImplicitAny errors:

```ts
const fn = (a, b) => {
  // Parameter 'a' implicitly has an 'any' type
  // \~ Parameter 'b' implicitly has an 'any' type
  console.log(a + b);
};
callWithRandomNumbers(fn);
```

The solution is either to add type annotations to the parameters:

```ts
const fn = (a: number, b: number) => {
  console.log(a + b);
};
callWithRandomNumbers(fn);
```

or to apply a type declaration to the entire function expression if one is available (see Item 12). If the function is only used in one place, prefer the inline form since it reduces the need for annotations.

### Things to Remember

- Be aware of how context is used in type inference.
- If factoring out a variable introduces a type error, maybe add a type annotation.
- If the variable is truly a constant, use a const assertion (as const). But be aware that this may result in errors surfacing at use, rather than definition.
- Prefer inlining values where it’s practical to reduce the need for type annotations.

## Item 25: Understand Evolving Types

In TypeScript, a variable’s type is generally determined when it is declared. After this, it can be narrowed (by checking if it is null, for instance; see Item 22), but it cannot expand to include new values. There is one notable exception to this, however, and that is “evolving types.” Understanding how these work will reduce the need for type annotations in your code and help you read TypeScript code that uses this convenient pattern.

In JavaScript, you might write a function to generate a range of numbers, like this:

```ts
function range(start, limit) {
  const nums = [];
  for (let i = start; i < limit; i++) {
    nums.push(i);
  }
  return nums;
}
```

When you convert this to TypeScript, it works exactly as you’d expect:

```ts
function range(start: number, limit: number) {
  const nums = [];
  for (let i = start; i < limit; i++) {
    nums.push(i);
  }
  return nums;
  // ^? const nums: number[]
}
```

Upon closer inspection, however, it’s surprising that this works! How does TypeScript know that the type of nums is number[] when it’s initialized as [], which could be an array of any type? Clearly TypeScript is not following its usual rules for deriving a type from a literal value (Item 20). Inspecting each of the three occurrences of nums to reveal its inferred type starts to tell the story:

```ts
function range(start: number, limit: number) {
  const nums = []; // ^? const nums: any[]
  for (let i = start; i < limit; i++) {
    nums.push(i); // ^? const nums: any[]
  }
  return nums; // ^? const nums: number[]
}
```

The type of nums starts as any[], an undifferentiated array. But after we push number values onto it, its type “evolves” to become number[].

This is distinct from narrowing (aka “refinement”). An empty array’s type can expand by pushing different elements onto it:

```ts
const result = [];
// ^? const result: any[]
result.push("a");
result;
// ^? const result: string[]
result.push(1);
result;
// ^? const result: (string | number)[]
```

With conditionals, the type can even vary across branches. Here you can see the same behavior with a simple value, rather than an array:

```ts
let value;
// ^? let value: any
if (Math.random() < 0.5) {
  value = /hello/;
  value; // ^? let value: RegExp
} else {
  value = 12;
  value; // ^? let value: number
}
value;
// ^? let value: number | RegExp
```

**NOTE**

> This behavior can be confusing to follow in your editor since the type is only “evolved” after you assign or push an element. Inspecting the type on the line with the assignment still shows any or any[].

This construct is a convenient way to reduce the need for type annotations. You can use it in your own code, and you should recognize it in code that you read. It’s sometimes known as “evolving any” because the variable implicitly has an any type, but this is not a dangerous any (more on that momentarily). It’s also sometimes called “evolving let” or “evolving arrays.”

Another case that triggers this “evolving” behavior is if a variable is initially set to null or undefined. This often comes up when you set a value in a try/catch block:

```ts
let value = null;
// ^? let value: any
try {
  value = doSomethingRiskyAndReturnANumber();
  value; // ^? let value: number
} catch (e) {
  console.warn("alas!");
}

value; // ^? let value: number | null
```

If you try to use an evolving type before you set it or push values onto it, you’ll get an implicit any error:

```ts
function range(start: number, limit: number) {
  const nums = [];
  // \~ Variable 'nums' implicitly has type 'any[]' in some
  // locations where its type cannot be determined
  if (start === limit) {
    return nums; // Variable 'nums' implicitly has an 'any[]' type
  }
  for (let i = start; i < limit; i++) {
    nums.push(i);
  }
  return nums;
}
```

Put another way, evolving types are only any when you write to them. If you try to read from them while they’re still any, you’ll get an error. This isn’t the scary any that Item 5 warned you about. It won’t spread through your application like other any types.

Implicit any types do not evolve through function calls. The arrow function here trips up inference:

```ts
function makeSquares(start: number, limit: number) {
  const nums = []; // Variable 'nums' implicitly has type 'any[]' in some locations
  range(start, limit).forEach((i) => {
    nums.push(i * i);
  });
  return nums; // Variable 'nums' implicitly has an 'any[]' type
}
```

Improved type inference is a good reason to prefer for-of loops to forEach loops in TypeScript. For this specific case, though, it would be better to use the built-in array map method to transform the array in a single statement, avoiding iteration and evolving types entirely. See Item 26 for more on how functional constructs can help types flow.

Evolving types come with all the usual caveats about type inference. Is the correct type for your array really (string|number)[]? Or should it be number[] and you incorrectly pushed a string? You may still want to provide an explicit type annotation to get better error checking instead of using an evolving type, or at least annotate the return type of your function to make sure that implementation errors don’t escape into the type signature (Item 18).

When you build an array by pushing elements onto it or set a value conditionally, consider whether you can use the evolving type construct to reduce the need for type annotations and to help types flow through your code.

### Things to Remember

- While TypeScript types typically only refine, the types of values initialized to null, undefined, or [] are allowed to evolve.
- Recognize and understand this construct where it occurs, and use it to reduce the need for type annotations in your own code.
- For better error checking, consider providing an explicit type annotation instead of using evolving types.

## Item 26: Use Functional Constructs and Libraries to Help Types Flow

JavaScript has never included the sort of standard library you find in Python, C, or Java. Over the years, many libraries have tried to fill the gap. jQuery provided helpers not just for interacting with the DOM but also for iterating and mapping over objects and arrays. Underscore focused more on providing general utility functions, and Lodash built on this effort. Today

libraries like Ramda continue to bring ideas from functional programming into the JavaScript world.

Some features from these libraries, such as map, flatMap, filter, and reduce, have made it into the JavaScript language itself. While these constructs (and the other ones provided by Lodash) are helpful in JavaScript and often preferable to a hand-rolled loop, this advantage tends to get even more lopsided when you add TypeScript to the mix. This is because their type declarations ensure that types flow through these constructs. With hand-rolled loops, you’re responsible for the types yourself.

For example, consider parsing some CSV data. You could do it in plain JavaScript in a somewhat imperative style:

```ts
const csvData = "...";
const rawRows = csvData.split("\n");
const headers = rawRows[0].split(",");
const rows = rawRows.slice(1).map((rowStr) => {
  const row = {};
  rowStr.split(",").forEach((val, j) => {
    row[headers[j]] = val;
  });
  return row;
});
```

More functionally minded JavaScripters might prefer to build the row objects with reduce:

```ts
const rows = rawRows
  .slice(1)
  .map((rowStr) =>
    rowStr
      .split(",")
      .reduce((row, val, i) => ((row[headers[i]] = val), row), {})
  );
```

This version saves a few characters but may be more cryptic depending on your sensibilities. Lodash’s zipObject function, which forms an object by “zipping” up arrays of keys and values, can tighten it even further:

```ts
import _ from "lodash";
const rows = rawRows
  .slice(1)
  .map((rowStr) => _.zipObject(headers, rowStr.split(",")));
```

Personally, I find this the clearest of all. But is it worth the cost of adding a dependency on a third-party library to your project and requiring all your coworkers to learn how to use it?

When you add TypeScript to the mix, it starts to tip the balance more strongly in favor of the Lodash solution.

Both vanilla JavaScript versions of the CSV parser produce the same error in TypeScript:

```ts
const rowsImperative = rawRows.slice(1).map((rowStr) => {
  const row = {};
  rowStr.split(",").forEach((val, j) => {
    row[headers[j]] = val;
    // \~ No index signature with a parameter of
    // type 'string' was found on type '{}'
  });
  return row;
});

const rowsFunctional = rawRows.slice(1).map((rowStr) =>
  rowStr.split(",").reduce(
    (row, val, i) => ((row[headers[i]] = val), row),
    // \~ No index signature with a parameter of
    // type 'string' was found on type'{}'
    {}
  )
);
```

The solution in each case is to provide a type annotation for {}, either {[column: string]: string} or Record<string, string>.

The Lodash version, on the other hand, passes the type checker without modification:

```ts
const rowsLodash = rawRows
  .slice(1)
  .map((rowStr) => _.zipObject(headers, rowStr.split(",")));
rowsLodash;
// ^? const rowsLodash: _.Dictionary<string>[]
```

Dictionary is a Lodash type alias. Dictionary<string> is the same as {[key: string]: string} or Record<string, string>. The important thing here is that the type of rows is exactly correct, no type annotations needed.

These advantages get more pronounced as your data munging gets more elaborate. For example, suppose you have an object containing a list of the players on each team in the NBA:

```ts
interface BasketballPlayer {
  name: string;
  team: string;
  salary: number;
}
declare const rosters: { [team: string]: BasketballPlayer[] };
```

To build a flat list using a loop, you might use concat with an array. This code runs fine but does not type check:

```ts
let allPlayers = [];
// Variable 'allPlayers' implicitly has type 'any[]'
// in some locations where its type cannot be determined
for (const players of Object.values(rosters)) {
  allPlayers = allPlayers.concat(players); // \~ Variable 'allPlayers' implicitly has an 'any[]' type
}
```

(The concat method does not trigger the “evolving” behavior described in Item 25.)

To fix the error you need to add a type annotation to allPlayers:

```ts
let allPlayers: BasketballPlayer[] = [];
for (const players of Object.values(rosters)) {
  allPlayers = allPlayers.concat(players); // OK
}
```

But a better solution is to use Array.prototype.flat:

```ts
const allPlayers = Object.values(rosters).flat(); // OK
// ^? const allPlayers: BasketballPlayer[]
```

The flat method flattens a multidimensional array. Its type signature is something like T[][] => T[].2 This version is the most concise and requires no type annotations. As an added bonus you can use const instead of let to prevent future mutations to the allPlayers variable.

Say you want to start with allPlayers and make a list of the highest-paid players on each team, ordered by salary.

Here’s a solution without Lodash. It requires a type annotation wherever you don’t use functional constructs:

```ts
const teamToPlayers: { [team: string]: BasketballPlayer[] } = {};
for (const player of allPlayers) {
  const { team } = player;
  teamToPlayers[team] = teamToPlayers[team] || [];
  teamToPlayers[team].push(player);
}
for (const players of Object.values(teamToPlayers)) {
  players.sort((a, b) => b.salary - a.salary);
}
const bestPaid = Object.values(teamToPlayers).map((players) => players[0]);
bestPaid.sort((playerA, playerB) => playerB.salary - playerA.salary);
console.log(bestPaid);
```

Here’s the output:

```ts
[
  { team: "GSW", salary: 51915615, name: "Stephen Curry" },
  { team: "PHO", salary: 47649433, name: "Kevin Durant" },
  { team: "DEN", salary: 47607350, name: "Nikola Jokić" },
  { team: "PHI", salary: 47607350, name: "Joel Embiid" },
  { team: "LAL", salary: 47607350, name: "LeBron James" },
];
```

Here’s the equivalent with Lodash:

```ts
const bestPaid = _(allPlayers)
  .groupBy((player) => player.team)
  .mapValues((players) => _.maxBy(players, (p) => p.salary)!)
  .values()
  .sortBy((p) => -p.salary)
  .value();
console.log(bestPaid.slice(0, 10));
// ^? const bestPaid: BasketballPlayer[]
```

In addition to being half the length, this code only requires a single non-null assertion (the type checker doesn’t know that the players array passed to \_.maxBy is non-empty). It makes use of a “chain,” a concept in Lodash and Underscore that lets you write a sequence of operations in a more natural order. Instead of writing:

```ts
_.c(_.b(_.a(v)));
```

you write:

```ts
_(v).a().b().c().value();
```

The \_(v) “wraps” the value, and the .value() “unwraps” it.

You can inspect each function call in the chain to see the type of the wrapped value. It’s always correct.

It’s not a coincidence that types flow so well through built-in functional constructs and those in libraries like Lodash. By avoiding mutation and returning new values from every call, they are able to produce new types as well (Item 19). To a large extent, the development of TypeScript has been driven by an attempt to accurately model the behavior of JavaScript libraries in the wild. Take advantage of all this work and use them!

### Things to Remember

- Use built-in functional constructs and those in utility libraries like Lodash instead of hand-rolled constructs to improve type flow, increase legibility, and reduce the need for explicit type annotations.

## Item 27: Use async Functions Instead of Callbacks to Improve Type Flow

Classic JavaScript modeled asynchronous behavior using callbacks. This led to the infamous “pyramid of doom”:

```ts
declare function fetchURL(
  url: string,
  callback: (response: string) => void
): void;
fetchURL(url1, function (response1) {
  fetchURL(url2, function (response2) {
    fetchURL(url3, function (response3) {
      // ...
      console.log(1);
    });
    console.log(2);
  });
  console.log(3);
});
console.log(4);

// Logs:
// 4
// 3
// 2
// 1
```

This code is heavily nested and, as you can see from the logs, the execution order is the opposite of the code order. This makes callback code hard to read. It gets even more confusing if you want to run the requests concurrently or bail when an error occurs.

ES2015 introduced the concept of a Promise to break the pyramid of doom. A Promise represents something that will be available in the future (they’re also sometimes called “futures”). Here’s the same code using Promises:

```ts
const page1Promise = fetch(url1);
page1Promise
  .then((response1) => {
    return fetch(url2);
  })
  .then((response2) => {
    return fetch(url3);
  })
  .then((response3) => {
    // ...
  })
  .catch((error) => {
    // ...
  });
```

Now there’s less nesting, and the execution order more directly matches the code order. It’s also easier to consolidate error handling and use higherorder tools like Promise.all.

ES2017 introduced the async and await keywords to make things even more concise:

```ts
async function fetchPages() {
  const response1 = await fetch(url1);
  const response2 = await fetch(url2);
  const response3 = await fetch(url3); //
}
```

The await keyword pauses execution of the fetchPages function until each Promise resolves. Within an async function, awaiting a Promise that rejects will throw an exception. This lets you use the usual try/catch machinery:

```ts
async function fetchPages() {
  try {
    const response1 = await fetch(url1);
    const response2 = await fetch(url2);
    const response3 = await fetch(url3);
    // ...
  } catch (e) {
    // ...
  }
}
```

Just like exceptions, Promise rejections in TypeScript are untyped.

async and await are supported by all recent JavaScript runtimes, but even if you target ES5 or earlier, the TypeScript compiler will perform some elaborate transformations to make async and await work. In other words, whatever your runtime, with TypeScript you can use async/await.

There are a few good reasons to prefer Promises or async/await to callbacks:

- Promises are easier to compose than callbacks.
- Types are able to flow through Promises more easily than callbacks.

If you want to fetch the pages concurrently, for example, you can compose Promises with Promise.all:

```ts
async function fetchPages() {
  const [response1, response2, response3] = await Promise.all([
    fetch(url1),
    fetch(url2),
    fetch(url3),
  ]);
  // ...
}
```

Using destructuring assignment with await is particularly nice in this context.

TypeScript is able to infer the types of each of the three response variables as Response. The equivalent code to issue the requests concurrently with callbacks requires more machinery and a type annotation:

```ts
function fetchPagesWithCallbacks() {
  let numDone = 0;
  const responses: string[] = [];
  const done = () => {
    const [response1, response2, response3] = responses;
    // ...
  };
  const urls = [url1, url2, url3];
  urls.forEach((url, i) => {
    fetchURL(url, (r) => {
      responses[i] = url;
      numDone++;

      if (numDone === urls.length) done();
    });
  });
}
```

Extending this to include error handling or to be as generic as Promise.all is challenging.

Type inference also works well with Promise.race, which resolves when the first of its input Promises resolves. You can use this to add timeouts to Promises in a general way:

```ts
function timeout(timeoutMs: number): Promise<never> {
  return new Promise((resolve, reject) => {
    setTimeout(() => reject("timeout"), timeoutMs);
  });
}
async function fetchWithTimeout(url: string, timeoutMs: number) {
  return Promise.race([fetch(url), timeout(timeoutMs)]);
}
```

The return type of fetchWithTimeout is inferred as Promise<Response>, no type annotations required. It’s interesting to dig into why this works: the return type of Promise.race is the union of the types of its inputs, in this case Promise<Response | never>. But taking a union with never (the empty set) is a no-op, so this gets simplified to Promise<Response>. When you work with Promises, all of TypeScript’s type inference machinery works to get you the right types.

You may occasionally need to use raw Promises, notably when you are wrapping a callback API like setTimeout. But if you have a choice, you should generally prefer async/await to raw Promises for two reasons:

It typically produces more concise and straightforward code.  
It enforces that async functions always return Promises.

This latter property helps avoid a confusing class of bugs. By definition, an async function always returns a Promise. This is true even if it doesn’t await anything. TypeScript can help you build an intuition for this:

```ts
async function getNumber() {
  return 42;
}
// ^? function getNumber(): Promise<number>
```

You can also create async arrow functions:

```ts
const getNumber = async () => 42; // ^? const getNumber: () => Promise<number>
```

The raw Promise equivalent is:

```ts
const getNumber = () => Promise.resolve(42); // ^? const getNumber: () => Promise<number>
```

While it may seem odd to return a Promise for an immediately available value, this actually helps enforce an important rule: a function should either always be run synchronously or always be run asynchronously. It should never mix the two.

To see how breaking this rule can lead to chaos, let’s try to add a cache to the fetchURL function:

```ts
// Don't do this!
const _cache: { [url: string]: string } = {};
function fetchWithCache(url: string, callback: (text: string) => void) {
  if (url in _cache) {
    callback(_cache[url]);
  } else {
    fetchURL(url, (text) => {
      _cache[url] = text;
      callback(text);
    });
  }
}
```

While invoking the callback immediately may seem like an optimization, the function is now extremely difficult for a client to use:

```ts
let requestStatus: "loading" | "success" | "error";
function getUser(userId: string) {
  fetchWithCache(`/user/${userId}`, (profile) => {
    requestStatus = "success";
  });
  requestStatus = "loading";
}
```

What will the value of requestStatus be after calling getUser? It depends entirely on whether the profile is cached. If it’s not, requestStatus will be set to “success.” If it is, it’ll get set to “success” and then set back to “loading.” Oops!

Using async for both functions enforces consistent behavior:

```ts
const _cache: { [url: string]: string } = {};
async function fetchWithCache(url: string) {
  if (url in _cache) {
    return _cache[url];
  }
  const response = await fetch(url);
  const text = await response.text();
  _cache[url] = text;
  return text;
}
let requestStatus: "loading" | "success" | "error";
async function getUser(userId: string) {
  requestStatus = "loading";
  const profile = await fetchWithCache(`/user/${userId}`);
  requestStatus = "success";
}
```

Now it’s completely transparent that requestStatus will end in “success.” It’s easy to accidentally produce half-synchronous code with callbacks or raw Promises, but difficult with async.3

Note that if you return a Promise from an async function, it will not get wrapped in another Promise: the return type will be Promise<T> rather than Promise Promise<T>>. Again, TypeScript will help you build an intuition for this:

```ts
async function getJSON(url: string) {
  const response = await fetch(url);
  const jsonPromise = response.json();
  return jsonPromise; // ^? const jsonPromise: Promise<any>
}
getJSON;
// ^? function getJSON(url: string): Promise<any>
```

### Things to Remember

- Prefer Promises to callbacks for better composability and type flow.
- Prefer async and await to raw Promises when possible. They produce more concise, straightforward code and eliminate whole classes of errors.
- If a function returns a Promise, declare it async.

## Item 28: Use Classes and Currying to Create New Inference Sites

Suppose you define an API using a TypeScript interface:

```ts
export interface SeedAPI {
  "/seeds": Seed[];
  "/seed/apple": Seed;
  "/seed/strawberry": Seed;
  // ...
}
```

This says that our API has a /seeds endpoint that returns an array of Seed objects. The /seed/apple and /seed/strawberry endpoints return one

Seed object.

Let’s write a function that issues requests to our API endpoints. This function should check that the endpoints exist, and it should return the correct type of data. This will be extremely helpful for making safe API calls from the client.

Here’s how that function should work:

```ts
// Correct usage:
const berry = await fetchAPI<SeedAPI>("/seed/strawberry"); // OK, returns Sed
// Incorrect usage; these should be errors:
fetchAPI<SeedAPI>("/seed/chicken"); // endpoint doesn't exist
const seed: Seed = await fetchAPI<SeedAPI>("/seeds"); // wrong return type
```

Here’s how you might declare fetchAPI (we’re not concerned about the implementation here, just the types):

```ts
declare function fetchAPI<API, Path extends keyof API>(
  path: Path
): Promise<API[Path]>;
```

Unfortunately, when you try to use this, you’ll get an error:

```ts
fetchAPI<SeedAPI>("/seed/strawberry");
// Expected 2 type arguments, but got 1.
```

The problem is that type inference in TypeScript is an all or nothing affair: either you can let TypeScript infer all the type parameters from usage, or you can specify all of them explicitly. There’s no in-between. (You can provide a default value for a type parameter, but this can only reference other type parameters; it can’t be inferred from usage.)

The API type parameter could be anything: since we’d like fetchAPI to work with any API, it can’t possibly be inferred. It has to be specified explicitly. So it would seem the only solution here is to write the Path type explicitly, too:

```ts
const berry = fetchAPI<SeedAPI, "/seed/strawberry">("/seed/strawberry"); // ok
// ^? const berry: Promise<Seed>
```

This works, but it’s frustratingly repetitive. Surely there’s a better way. We need to somehow separate the place where we explicitly write the API type parameter from the place where we infer the Path type parameter.

There are two standard ways to do this: classes and currying.

### Classes

Classes are very good at capturing bits of state. They spare you from having to repeatedly pass the same state to a set of related functions (the class’s methods). In TypeScript, it turns out that classes are also very good at capturing types.

Here’s how you can define a class to solve this problem:

```ts
declare class ApiFetcher<API> {
  fetch<Path extends keyof API>(path: Path): Promise<API[Path]>;
}
```

And here’s how you use it:

```ts
const fetcher = new ApiFetcher<SeedAPI>();
const berry = await fetcher.fetch("/seed/strawberry"); // OK
// ^? const berry: Seed
fetcher.fetch("/seed/chicken");
//
// Argument of type '"/seed/chicken"' is not assignable to type 'keyof SeedAPI'
const seed: Seed = await fetcher.fetch("/seeds");
// \~\~\~\~ Seed[] is not assignable to Seed
```

This produces exactly the errors we were hoping for. (You also need to implement the class, of course! We’re just focusing on the types here.)

What used to be a function that needed two generic type parameters is now a class with one generic type parameter that you specify explicitly, and a method with one generic type parameter that’s inferred. TypeScript is perfectly happy to let you bind the API type parameter when you call the class’s constructor (new ApiFetcher See API>()) and then infer Path when you call the fetch method.

Using classes to create a distinct binding site is particularly effective when you have multiple methods that all require the same type parameter.

### Currying

Fun fact: programming languages don’t really need functions with more than one parameter. Instead of:

```ts
declare function getDate(mon: string, day: number): Date;
getDate("dec", 25);
```

you could write a function that returns another function:

```ts
declare function getDate(mon: string): (day: number) => Date;
getDate("dec")(25);
```

Note the slightly different syntax to call the second version. This practice is known as currying, after the logician Haskell Curry, who always disavowed having come up with the technique.

Currying gives us the flexibility we need to introduce as many inference sites as we like. Each function call can infer new type parameters.

Here’s how you can rework fetchAPI using functions that return functions:

```ts
declare function fetchAPI<API>(): <Path extends keyof API>(
  path: Path
) => Promise<API[Path]>;
```

Now fetchAPI takes no parameters, but it returns a function that takes one. Here’s how you use it:

```ts
const berry = await fetchAPI<SeedAPI>()("/seed/strawberry"); // OK // ^? const berry: Seed
fetchAPI<SeedAPI>()("/seed/chicken");
//
// Argument of type '"/seed/chicken"' is not assignable to type 'keyof SeedAPI'
//
const seed: Seed = await fetchAPI<SeedAPI>()("/seeds");
// \~\~\~\~ Seed[] is not assignable to Seed
```

Just like the class solution, this works in the case where we want it to and produces the desired error in the others. You can use an intermediate variable to separate out the two function calls to reduce repetition:

```ts
const fetchSeedAPI = fetchAPI<SeedAPI>();
const berry = await fetchSeedAPI("/seed/strawberry"); // ^? const berry: Seed
```

The currying approach isn’t as distinct from the class approach as it might initially appear. If you use a different name and return an object type instead of a function, they look nearly identical:

```ts
declare function apiFetcher<API>(): {
  fetch<Path extends keyof API>(path: Path): Promise<API[Path]>;
};
const fetcher = apiFetcher<SeedAPI>();
fetcher.fetch("/seed/strawberry"); // OK
```

The only difference in usage between this and the class example is the keyword new.

If you want to specify some generic parameters explicitly while allowing others to be inferred, classes and currying are your two options.

So which one should you prefer? Ultimately it’s up to you. Whichever one feels most comfortable and produces the API you find most convenient is the way to go. The currying approach does have at least one advantage in the context of TypeScript, however: it creates a scope in which you can define local type aliases:

```ts
function fetchAPI<API>() {
  type Routes = keyof API & string; // local type alias
  return <Path extends Routes>(path: Path): Promise<API[Path]> =>
    fetch(path).then((r) => r.json());
}
```

You can’t do this with just a declaration: only the implementation introduces a new scope. Local type aliases like Routes can cut down on repetition involving complex type expressions. There is no equivalent of this for classes.

### Things to Remember

- or functions with multiple type parameters, inference is all or nothing: either all type parameters are inferred or all must be specified explicitly.
- To get partial inference, use either classes or currying to create a new inference site.
- Prefer the currying approach if you’d like to create a local type alias.
